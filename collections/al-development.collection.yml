id: al-development
name: AL Development for Business Central
description: AI Native Development toolkit implementing the A-Instructions Architecture framework with 38 Agent Primitives across 3 systematic layers. Provides Markdown Prompt Engineering through Instructions (9), Agentic Workflows (18), Agents (7), Orchestra System (4) and Context Engineering via applyTo patterns for optimal LLM performance in Business Central development. Includes multi-agent TDD orchestration and complete workflow documentation.
tags: [al, business-central, dynamics365, erp, microsoft, ai-native, a-instructions, agent-primitives, context-engineering, copilot, tdd, orchestration]

items:
    # Layer 2: Agent Primitives - Instructions (7 files)
    # Context Engineering via applyTo patterns for modular context loading
  - path: instructions/al-guidelines.instructions.md
    kind: instruction
  - path: instructions/al-code-style.instructions.md
    kind: instruction
  - path: instructions/al-naming-conventions.instructions.md
    kind: instruction
  - path: instructions/al-performance.instructions.md
    kind: instruction
  - path: instructions/al-error-handling.instructions.md
    kind: instruction
  - path: instructions/al-events.instructions.md
    kind: instruction
  - path: instructions/al-testing.instructions.md
    kind: instruction

  # Layer 2: Agent Primitives - Agentic Workflows (18 files)
  # Complete systematic processes with validation gates and AL tool access
  - path: prompts/al-initialize.prompt.md
    kind: prompt
  - path: prompts/al-diagnose.prompt.md
    kind: prompt
  - path: prompts/al-build.prompt.md
    kind: prompt
  - path: prompts/al-events.prompt.md
    kind: prompt
  - path: prompts/al-performance.prompt.md
    kind: prompt
  - path: prompts/al-performance.triage.prompt.md
    kind: prompt
  - path: prompts/al-permissions.prompt.md
    kind: prompt
  - path: prompts/al-migrate.prompt.md
    kind: prompt
  - path: prompts/al-pages.prompt.md
    kind: prompt
  - path: prompts/al-spec.create.prompt.md
    kind: prompt
  - path: prompts/al-pr-prepare.prompt.md
    kind: prompt
  - path: prompts/al-copilot-capability.prompt.md
    kind: prompt
  - path: prompts/al-copilot-promptdialog.prompt.md
    kind: prompt
  - path: prompts/al-copilot-test.prompt.md
    kind: prompt
  - path: prompts/al-copilot-generate.prompt.md
    kind: prompt
  - path: prompts/al-translate.prompt.md
    kind: prompt
  - path: prompts/al-context.create.prompt.md
    kind: prompt
  - path: prompts/al-memory.create.prompt.md
    kind: prompt

  # Layer 3: Integration Guide & Documentation (2 files)
  # Master coordination documents linking all Agent Primitives
  - path: instructions/copilot-instructions.md
    kind: instruction
    description: |
      Master integration document for GitHub Copilot. This is the collection's main coordination hub,
      linking all 37 Agent Primitives and providing usage patterns for the complete AL Development Collection.
      
      Auto-loaded as .github/copilot-instructions.md per GitHub Copilot conventions.
      Contains architecture overview, agent coordination, workflow examples, and critical AL patterns.
  
  - path: docs/workflows/complete-development-flow.md
    kind: instruction
    description: |
      Complete visual guide for development workflows from requirements to deployment.
      Includes decision tree, flow patterns (Simple/Moderate/Complex), specialized flows (API/Copilot/Performance),
      end-to-end examples, and agent interaction matrix.
      
      Use as reference to understand when to use workflows vs Orchestra, how agents interact,
      and complete workflow patterns for different feature complexities.

  # Layer 2: Agent Primitives - Agents (7 files)
  # Role-based specialists with MCP tool boundaries preventing cross-domain operations
  - path: agents/al-orchestrator.agent.md
    kind: agent
    usage: deprecated
    description: |
      Strategic router and workflow coordinator implementing Markdown Prompt Engineering principles. This is your entry point for complex tasks - it analyzes requirements and orchestrates the right combination of Agent Primitives (Instructions, Workflows, Agents) for optimal results.

      Orchestrates Agent Primitives through:
      - Context Loading - Analyzes requirements and loads relevant Instructions
      - Workflow Routing - Recommends appropriate Agentic Workflows for execution
      - Mode Coordination - Routes to specialized Agents for strategic work
      - Multi-Phase Planning - Creates systematic workflows for complex features

      Implements Context Engineering by:
      - Selective primitive activation based on task complexity
      - Preventing context window pollution through strategic routing
      - Recommending parallel vs sequential execution patterns

      Example usage:
      ```markdown
      ---
      mode: al-orchestrator
      title: Build AI-powered API for sales forecasting
      ---
      
      I need to create an API that uses AI to forecast sales based on historical data.
      I'm not sure where to start or which tools I need.
      ```

      To get the best results:
      - Provide context about what you're trying to accomplish
      - Mention any constraints (timeline, existing code, team size)
      - Let the orchestrator analyze before jumping into implementation

  - path: agents/al-architect.agent.md
    kind: agent
    usage: recommended
    description: |
      Solution architecture and design specialist applying Markdown Prompt Engineering for structured technical decision-making. Uses semantic markdown (headers, lists, links) to create clear architectural documentation and design rationale.

      Tool Boundaries (professional licensing model):
      - CAN: Design solutions, analyze patterns, recommend approaches
      - CANNOT: Execute builds, deploy code, run tests (delegates to workflows)

      Auto-loads Instructions for context:
      - al-guidelines.instructions.md (BC architectural patterns)
      - al-code-style.instructions.md (feature-based structure)
      - al-performance.instructions.md (scalability considerations)

      Ideal for (strategic thinking, not execution):
      - Planning new feature architecture
      - Designing data models and table structures
      - Evaluating integration strategies
      - Making strategic technical decisions
      - Reviewing and refactoring existing designs

      Example usage:
      ```markdown
      ---
      mode: al-architect
      title: Design multi-company approval workflow
      ---
      
      #file: src/Sales/SalesHeader.Table.al
      #file: src/Approval/ApprovalEntry.Table.al
      
      Design an approval workflow system that:
      - Works across multiple companies
      - Supports delegation
      - Sends email notifications
      - Integrates with existing sales documents
      ```

      To get the best results:
      - Include relevant existing code in context
      - Specify business requirements clearly
      - Mention scalability and data volume expectations
      - Ask about alternatives and trade-offs

  - path: agents/al-debugger.agent.md
    kind: agent
    usage: optional
    description: |
      Systematic debugging specialist applying Markdown Prompt Engineering for structured problem diagnosis. Uses semantic markdown to create clear diagnostic trees and root cause analysis documentation.

      Tool Boundaries (professional licensing model):
      - CAN: Analyze issues, diagnose root causes, recommend fixes
      - CANNOT: Execute code, run debuggers directly (recommends workflows)

      Recommends Agentic Workflows:
      - al-debug.prompt.md (for attaching debugger)
      - al-performance.prompt.md (for profiling bottlenecks)
      - al-troubleshoot.prompt.md (for common patterns)

      Ideal for (diagnosis, not execution):
      - Diagnosing bugs and unexpected behavior
      - Root cause analysis of complex issues
      - Investigating intermittent problems
      - Understanding code execution flow
      - Performance bottleneck identification

      Example usage:
      ```markdown
      ---
      mode: al-debugger
      title: Debug event subscriber not firing
      ---
      
      #file: src/Sales/SalesEventHandler.Codeunit.al
      
      My OnBeforePostSalesDoc event subscriber isn't being called.
      The signature looks correct but it never executes.
      ```

      To get the best results:
      - Include error messages and symptoms
      - Share relevant code in context
      - Describe steps to reproduce
      - Mention what you've already tried

  - path: agents/al-tester.agent.md
    kind: agent
    usage: optional
    description: |
      Testing strategy and TDD specialist applying Markdown Prompt Engineering for structured test planning. Uses semantic markdown to create clear test scenarios and coverage matrices.

      Tool Boundaries (professional licensing model):
      - CAN: Design test strategies, plan scenarios, review coverage
      - CANNOT: Execute tests, run code (delegates to workflows)

      Auto-loads Instructions for context:
      - al-testing.instructions.md (AL-Go structure, test patterns)
      
      Implements Context Engineering:
      - Only generates tests when explicitly requested
      - Preserves context for test design over implementation

      Ideal for (strategy, not execution):
      - Designing test strategies
      - Implementing test-driven development (TDD)
      - Creating comprehensive test suites
      - Improving test coverage
      - Setting up test automation

      Example usage:
      ```markdown
      ---
      mode: al-tester
      title: Create test suite for sales posting logic
      ---
      
      #file: src/Sales/SalesPost.Codeunit.al
      
      I need comprehensive tests for the sales posting logic.
      What test scenarios should I cover?
      ```

      To get the best results:
      - Share the code you want to test
      - Specify if you want unit, integration, or UI tests
      - Mention any specific edge cases to cover
      - Indicate your test coverage goals

  - path: agents/al-api.agent.md
    kind: agent
    usage: optional
    description: |
      RESTful API design specialist applying Markdown Prompt Engineering for structured API contracts. Uses semantic markdown to create clear endpoint documentation and integration patterns.

      Tool Boundaries (professional licensing model):
      - CAN: Design APIs, plan endpoints, document contracts
      - CANNOT: Execute builds, test APIs directly (recommends workflows)

      Auto-loads Instructions for context:
      - al-error-handling.instructions.md (proper error responses)
      - al-performance.instructions.md (API optimization patterns)

      Recommends Agentic Workflows:
      - al-permissions.prompt.md (for API security setup)
      - al-build.prompt.md (for deployment)

      Ideal for (design and implementation guidance):
      - Designing API endpoints and contracts
      - Implementing API pages (v2.0)
      - Setting up authentication and security
      - API versioning strategies
      - External system integrations

      Example usage:
      ```markdown
      ---
      mode: al-api
      title: Create API for mobile app integration
      ---
      
      I need to expose sales orders to a mobile app.
      The app needs to:
      - List orders by customer
      - Get order details with lines
      - Create new orders
      - Update order status
      ```

      To get the best results:
      - Describe the API consumer (mobile app, external system, etc.)
      - Specify required operations (CRUD, custom actions)
      - Mention authentication requirements
      - Include performance expectations

  - path: agents/al-copilot.agent.md
    kind: agent
    usage: optional
    description: |
      AI-powered feature specialist applying advanced Markdown Prompt Engineering for Copilot experiences. Expert in prompt engineering patterns, context loading strategies, and responsible AI implementation.

      Tool Boundaries (professional licensing model):
      - CAN: Design AI features, engineer prompts, plan integrations
      - CANNOT: Execute code, deploy services (recommends workflows)

      Coordinates with other Agent Primitives:
      - al-architect.agent.md (for AI integration architecture)
      - al-error-handling.instructions.md (for AI service failures)

      Implements meta-level Context Engineering:
      - Designs prompt engineering patterns for end-user Copilot features
      - Plans context optimization strategies for AI features

      Ideal for (AI feature design and prompt engineering):
      - Designing Copilot user experiences
      - Implementing Azure OpenAI integration
      - Prompt engineering for business scenarios
      - Creating AI-powered suggestions and insights
      - Implementing responsible AI practices

      Example usage:
      ```markdown
      ---
      mode: al-copilot
      title: Add AI sales forecasting to customer card
      ---
      
      I want to add an AI-powered sales forecast feature that:
      - Analyzes historical sales data
      - Provides monthly forecasts
      - Suggests optimal order quantities
      - Explains its reasoning
      ```

      To get the best results:
      - Describe the AI feature from user perspective
      - Specify what data the AI should analyze
      - Mention desired output format
      - Include any responsible AI considerations
      - Ask about prompt engineering best practices

  - path: agents/al-developer.agent.md
    kind: agent
    usage: recommended
    description: |
      Tactical implementation specialist with full MCP tool access for executing code changes. Focuses on clean execution within established patterns without making strategic architectural decisions.

      Tool Boundaries (professional licensing model):
      - CAN: Create/edit files, build, publish, test, refactor, fix bugs
      - CANNOT: Design architectures, test strategies, API contracts (delegates to specialized modes)

      Full AL MCP Tool Access:
      - Build tools: al_build, al_buildall, al_package, al_publish, al_incrementalpublish
      - Environment: al_downloadsymbols, al_downloadsource
      - Code generation: al_generatepermissionset, al_generatemanifest
      - Debugging: al_debugWithoutpublish, snapshot debugging tools
      - Performance: al_generatecpuprofile

      Auto-loads Instructions for quality:
      - al-code-style.instructions.md (2-space indent, feature folders)
      - al-naming-conventions.instructions.md (26-char limits)
      - al-performance.instructions.md (SetLoadFields patterns)
      - al-error-handling.instructions.md (TryFunctions)
      - al-events.instructions.md (event patterns)

      Implements systematic workflow:
      1. Load context (search, usages, problems)
      2. Implement following auto-instructions
      3. Build and validate continuously
      4. Test integration
      5. Delegate strategic decisions to specialized modes

      Ideal for (tactical execution):
      - Implementing features from specifications
      - Creating AL objects (tables, pages, codeunits)
      - Extending base BC objects (table/page extensions)
      - Implementing event subscribers
      - Refactoring existing code
      - Fixing bugs and errors
      - Building and publishing extensions

      Example usage:
      ```markdown
      ---
      mode: al-developer
      title: Implement customer email validation
      ---
      
      #file: src/Sales/Customer.TableExt.al
      
      Implement email validation on the Customer table extension:
      - Add event subscriber for OnBeforeValidateEvent on Email field
      - Validate email format using regex
      - Show error if invalid
      - Build and test
      ```

      To get the best results:
      - Provide clear specifications or reference existing patterns
      - Include relevant files in context
      - Specify if you need builds/tests run
      - Mention any specific business rules
      - Let the mode delegate if architectural decisions arise

  # Layer 2: Agent Primitives - Orchestra System (4 files)
  # Multi-agent TDD workflow coordination following GitHub Copilot Orchestra pattern
  # Adapted for AL development with Business Central best practices
  - path: agents/orchestration/al-conductor.agent.md
    kind: agent
    usage: recommended
    description: |
      Main orchestration agent managing Planning → Implementation → Review → Commit cycle for AL development.
      Delegates to specialized subagents (planning, implementation, review) for structured TDD workflow.
      Enforces Test-Driven Development and quality gates for Business Central extensions.
      
      Use for complex multi-phase features requiring structured workflow with quality enforcement.
      Creates plan files in .github/plans/ with complete documentation trail.
      
      Key Features:
      - Multi-phase planning with AL-specific context (base objects, events, AL-Go structure)
      - TDD enforcement: Red (failing tests) → Green (minimal code) → Refactor
      - Quality gates: Automated code review before each commit
      - Documentation: Auto-generates plan, phase completion, and final summary files
      - AL best practices: Event-driven, naming conventions, performance patterns
      
      Example usage:
      ```markdown
      Use al-conductor mode
      
      I need to add email validation to the Customer table using event subscribers.
      The validation should:
      - Use regex pattern matching
      - Allow empty emails (Email is optional in BC)
      - Normalize to lowercase
      - Show user-friendly error message
      ```
      
      Workflow:
      1. User describes feature → Conductor delegates to planning subagent
      2. Planning returns AL context → Conductor creates multi-phase plan
      3. User approves plan → Conductor orchestrates implementation phases
      4. Each phase: Implement → Review → Commit (with user approval)
      5. Plan completion → Documentation summary generated
      
      To get the best results:
      - Provide clear business requirements and constraints
      - Review and approve the plan before implementation starts
      - Answer open questions during planning phase
      - Commit after each phase (don't skip commit gates)
      - Trust the TDD process (tests first, then minimal code)
      
  - path: agents/orchestration/al-planning-subagent.agent.md
    kind: agent
    usage: optional
    description: |
      AL-aware research and context gathering subagent for Business Central development.
      Analyzes codebase structure, dependencies, AL objects, event architecture, and AL-Go structure.
      Returns structured findings to Conductor for plan creation.
      
      Called automatically by al-conductor. Not for direct use by developers.
      
      Responsibilities:
      - Identify relevant AL objects (Tables, Pages, Codeunits, etc.)
      - Map event architecture (subscribers, publishers, integration points)
      - Verify AL-Go structure (app/ vs test/ separation)
      - Analyze dependencies (.alpackages/, app.json, symbols)
      - Document performance considerations (large tables, SetLoadFields)
      - Suggest 2-3 implementation options with pros/cons
      
      Returns structured findings with:
      - Base BC objects and existing extensions
      - Event subscribers/publishers available
      - AL-Go project structure
      - Naming and organizational patterns
      - Performance context
      - Implementation recommendations
      
  - path: agents/orchestration/al-implement-subagent.agent.md
    kind: agent
    usage: optional
    description: |
      TDD-focused implementation subagent with full AL MCP tool access for Business Central.
      Executes implementation tasks following strict Test-Driven Development with AL patterns.
      Works autonomously within phase boundaries set by Conductor.
      
      Called automatically by al-conductor. Not for direct use by developers.
      
      TDD Workflow:
      1. RED: Write failing tests in /test project → Verify failure
      2. GREEN: Write minimal AL code in /app project → Verify tests pass
      3. REFACTOR: Apply AL patterns, optimize, document
      4. VALIDATE: Run full test suite, check for regressions
      
      AL Patterns Enforced:
      - Event-driven architecture (TableExtension, PageExtension, Event Subscribers)
      - AL-Go structure (app/ and test/ separation)
      - Naming conventions (26-char limit, PascalCase)
      - Performance patterns (SetLoadFields, early filtering, temporary tables)
      - Error handling (TryFunctions, error labels, telemetry)
      
      Full AL MCP Tool Access:
      - al_build, al_publish, al_incremental_publish (compilation & deployment)
      - al_debug_without_publish (quick debugging)
      - runCommands, runTasks (test execution, linting)
      
      Uses Claude Haiku 4.5 for cost-efficient execution.
      
  - path: agents/orchestration/al-review-subagent.agent.md
    kind: agent
    usage: optional
    description: |
      AL code review subagent validating implementation quality for Business Central.
      Checks test coverage, AL patterns, performance, and BC best practices.
      Returns structured review: APPROVED / NEEDS_REVISION / FAILED.
      
      Called automatically by al-conductor. Not for direct use by developers.
      
      AL-Specific Review Checklist:
      - Event-Driven Architecture: No base object modifications (CRITICAL)
      - Naming Conventions: 26-character limit respected (MAJOR if violated)
      - AL-Go Structure: App and test code properly separated (MAJOR if mixed)
      - Performance Patterns: SetLoadFields, early filtering applied (MAJOR for large tables)
      - Error Handling: TryFunctions for external calls, error labels used
      - Test Coverage: Happy path, error cases, edge cases covered (MAJOR if missing)
      - Feature Organization: Code organized by capability, not object type
      
      Review Output:
      - Status: APPROVED / NEEDS_REVISION / FAILED
      - Issues: CRITICAL / MAJOR / MINOR with file/line references
      - AL Best Practices Compliance: Checklist results
      - Test Results: Pass/fail status for all tests
      - Recommendations: Specific improvements (even when approved)
      - Next Steps: What Conductor should do next
      
      Uses Claude Sonnet 4.5 for thorough analysis.

display:
  ordering: manual
  show_badge: true